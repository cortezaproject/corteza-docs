== developer docs

Corteza messagebus offers the functionality to pass the messages from producers to consumers via message queues.
Funcionality is mainly internaly used with workflows via eventbus, but it could easily be used elsewhere.

high level diagram of queues

=== Queue
Message queue is defined with a *name*, *consumer* and *metadata*. The metadata is specific to each queue and is a mechanism
to provide contextual data to either the producer or consumer, but for now, only the polling delay is internally used.

=== Queue producer
Producers are the source of the incoming messages into the queue and should be implemented on a per-need basis. The Corteza messagebus
is internally using producers as handlers in workflows, so you can use the *Queue message send* handler with the appropriate
queue name and payload as arguments.

=== Queue consumer
The messagebus consumers are the adapters, that are implemented for a specific message destination, currently there is eventbus and
store support (default store per-Corteza defined on system level).

Consumers are stored in the messagebus package ```pkg/messagebus```.

=== Queue message lifecycles

==== Write to consumer

.Workflow example
 - messagebus service already preloads queue settings on boot
 - register the queue handler (see more below in #read from producer)
 - use the messagebus global service and ```push()``` payload to specific queue
 - payload gets pushed to an internal messagebus channel
 - specific consumer (store) that is specified for this queue is invoked
 - the consumer adapter pushes the payload to the destination
    * could be another queue in store
    * could be eventbus which triggers another workflow

==== Read from producer

The producers are implementation specific, Corteza uses a specific one as a workflow queue handler, where the payload is being written via messagebus facility to the queue.

===== Polling delay metadata
This is the only metadata that is used in the store producer as means to poll the db data until a subscriber is implemented. This way, we can get contextual data to the producer / consumer.



=== Internal Corteza messagebus to eventbus flow

Corteza workflows currently has the possibility to incorporate messagebus capabilities via eventbus mechanism. The
messagebus producer can in this case be an eventbus handler, in our case the already implemented queue trigger (see more in #workflows).

The queue handler (producer in the diagram) needs to be triggered to write to messagebus queue, this is done via eventbus mechanism. Once the payload reaches producer, the payload and the queue name are both pushed to messagebus service internal channel (via exposed method).

[NOTE]
====
There is no validation on the payload, it is handled as a []byte type and any marshaling or decoding needs to be done
on the consumer side.
====

Once the messagebus service fetches the appropriate payload from the internal channel, it matches the already registered and instantiated consumer handler for that queue. The payload is then processed in the consumer specific logic.

The message flow in our example is not yet finished, since we also have an eventbus consumer, so the payload is again transformed (in workflow) and a different payload is then being pushed in to some other queue.

An example would be a website registration page that pushes user github id on the queue (lets call it queue ```users_github```). Eventbus would then get the payload with the id, fetch the user metadata from github, write to store and on success, write via eventbus to another queue with the user avatar url (lets call it ```users_avatars```). The eventbus would trigger a new workflow on that queue that would fetch binary data from urls and write it to designated store.

```
@startuml
skinparam responseMessageBelowArrow true

participant "Eventbus" as eb
box "Messagebus" #f7f7f7
participant "Producer" as producer
participant "Service" as mb
participant "Consumer" as consumer

activate eb
eb -> producer: trigger in workflow

activate producer
producer -> mb: send payload from queue handler
deactivate producer
deactivate eb

mb -> mb: add to channel
mb -> mb: get payload from channel, consumer from payload
mb -> consumer: send payload
deactivate mb

activate consumer
consumer -> eb: push parsed payload event
deactivate consumer

end box
@enduml
```

=== Messagebus queues as a distributed pipeline

To continue from our previous example, once our website would grow and we would scale on our instances, so to would we be able to offload (should be choose so) any work from workflows to a designated service or our extended infrastructure on a service provider.

Similar to the previous scenario, on user registration, the messagebus consumer would need to know how to push the payloads to the queueing mechanism on the service provider (ie Amazon SQS / SNS). The infrastructure that we set up would then process all the payloads and use our specific messagebus producer (ie a lambda handler written in python) to send the payload to another Corteza instance via API sink mechanism.

Corteza workflows include a trigger for the API sink also (#link to the api sink docs), so the payload would then be processed in another workflow, according to the business logic of the whole flow.

A diagram showing capabilities with creating pipelines between different queueing mechanisms

```
@startuml
node "Domain" {
package "Corteza 1" {
  [Queue "users"]
}

package "Corteza 2" {
  [Queue "administrators"]
}

}

package "Corteza 3" {
  [Corteza API sink]
  [Queue "processed user data"]
}

cloud "Cloud service provider" {
  [Queueing mechanism]
  [Worker]
}

database "Store" {
    [Enriched user data]
}

[Queue "users"] --> [Queueing mechanism]
[Queue "administrators"] --> [Queueing mechanism]
[Queueing mechanism] --> [Worker]
[Worker] --> [Corteza API sink]
[Corteza API sink] --> [Queue "processed user data"]
[Queue "processed user data"] --> [Enriched user data]
@enduml
```
